{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc10e69f-d5bc-43a3-ae70-a4aadef788e6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1. Preparing Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b56ced5-866f-499b-9cd8-fa24c2a588be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lime\n",
    "# This command installs the LIME (Local Interpretable Model-agnostic Explanations) library for Python, which is used for explaining the predictions of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4fd3c3-05a5-4a77-ba82-51ece52c8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn\n",
    "# This command installs the imbalanced-learn library, which provides tools to handle imbalanced datasets in machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535472da-f2d3-4a84-ada6-259048c2d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost\n",
    "# This command installs the XGBoost library, which is an optimized distributed gradient boosting library designed to be highly efficient, flexible, and portable for machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd736b6-1fec-447b-84f1-10c3c26c4257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "from lime.lime_tabular import LimeTabularExplainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceae709-98f3-4060-a0ab-f400aa2c5186",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb8790-7ea1-4d50-bede-c7366c35d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = r'/PhiUSIIL_Phishing_URL_Dataset.csv' # Update with your file path\n",
    "\n",
    "df = pd.read_csv(file_path) # Load the dataset into a pandas DataFrame\n",
    "df.info() # Display information about the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c7b75a-dccb-420d-bd06-5a295022d2cc",
   "metadata": {},
   "source": [
    "## 2. Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ccfe7d-fe88-4425-905d-2e4d7f09aa1f",
   "metadata": {},
   "source": [
    "### Drop Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a144b9-b5c5-463d-9597-e595cc3147bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ['FILENAME', 'URL', 'DOMAIN', 'TLD', 'TITLE'] columns, as they are not needed for the model training, and causes issues with the model\n",
    "\n",
    "df = df.select_dtypes(include=['number']).copy()\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "df.shape # Check the shape of the DataFrame after removing duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec511b2f-c00d-43b7-8660-ad3d29abbd6d",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d009fea5-c3af-4c6e-9a65-a2345455de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "X = df.iloc[:, :-1]  # All rows, all columns except the last\n",
    "y = df.iloc[:, -1]   # All rows, only the last column\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")   # Stratify to maintain class distribution\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")  # Print shapes of training set\n",
    "print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\") # Print shapes of testing set\n",
    "\n",
    "print(\"\\nSample of X_train:\\n\")\n",
    "print(X_train.head()) # Display first few rows of X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fda703-3dad-4e20-a184-d06fbb7d6b8a",
   "metadata": {},
   "source": [
    "### Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eaf39c-6656-4783-be6b-eb51fefe49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaler\n",
    "scaler = StandardScaler() # Standardize features by removing the mean and scaling to unit variance\n",
    "\n",
    "# Fit only on training data\n",
    "X_train_scaled = scaler.fit_transform(X_train) # Fit to data, then transform it.\n",
    "X_test_scaled = scaler.transform(X_test) # Perform standardization by centering and scaling\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(f\"Shape after scaling: X_train: {X_train_scaled.shape}, X_test: {X_test_scaled.shape}\")\n",
    "\n",
    "print(\"\\nSample of X_train_scaled:\\n\")\n",
    "X_train_scaled.head() # Display the first few rows of the scaled training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a15fd-47ea-42ca-b12b-2e1e7d016003",
   "metadata": {},
   "source": [
    "### Compare SMOTE, ADASYN, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba192eb9-eaa0-429e-9a29-8cd09221d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check original class distribution\n",
    "print(\"Original class distribution in training set:\")\n",
    "print(y_train.value_counts()) # Display the count of each class in the training set\n",
    " \n",
    "# Apply SMOTE\n",
    "X_smote, y_smote = SMOTE(random_state=42).fit_resample(X_train_scaled, y_train) # Apply SMOTE to the scaled training data\n",
    "print(\"\\nAfter SMOTE:\")\n",
    "print(y_smote.value_counts()) # Display the count of each class after applying SMOTE\n",
    "\n",
    "# Apply ADASYN\n",
    "X_adasyn, y_adasyn = ADASYN(random_state=42).fit_resample(X_train_scaled, y_train)\n",
    "print(\"\\nAfter ADASYN:\")\n",
    "print(y_adasyn.value_counts())\n",
    "\n",
    "# Apply BorderlineSMOTE\n",
    "X_bsmote, y_bsmote = BorderlineSMOTE(random_state=42, kind='borderline-1').fit_resample(X_train_scaled, y_train)\n",
    "print(\"\\nAfter BorderlineSMOTE:\")\n",
    "print(y_bsmote.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936846c-fa30-4eeb-b1bc-54bda2c3768b",
   "metadata": {},
   "source": [
    "### Apply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b40a22-be2b-4b66-9a2a-dff535fa6039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE\n",
    "X_train_resampled, y_train_resampled = SMOTE(random_state=42).fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Shape after SMOTE resampling: {X_train_resampled.shape}\")\n",
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(y_train_resampled.value_counts()) # Display the count of each class after SMOTE resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f1798-4948-4e33-b963-122cef6c0b38",
   "metadata": {},
   "source": [
    "### Dataset Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d14a8a-a08a-46c3-9ca1-2dfa2aa8a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize SelectKBest\n",
    "k = 20  # Change the number of features you want to select\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "# Fit on resampled training data\n",
    "X_train_selected = selector.fit_transform(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Apply the same selection on test data\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Get indices and scores of selected features\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "scores = selector.scores_\n",
    "\n",
    "# Get the original feature names\n",
    "feature_names = X_train_scaled.columns\n",
    "selected_feature_names = [feature_names[i] for i in selected_indices]\n",
    "\n",
    "# Print selected features\n",
    "print(f\"Top {k} selected features:\\n\")\n",
    "print(selected_feature_names)\n",
    "\n",
    "print(\"\\nShape of selected training set:\", X_train_selected.shape)\n",
    "print(\"Shape of selected testing set:\", X_test_selected.shape)\n",
    "\n",
    "# Plot scores\n",
    "# --------------------------------------------------\n",
    "# Create figure 1920x1080 pixels at 100 DPI\n",
    "plt.figure(figsize=(19.2, 10.8))\n",
    "\n",
    "# Plot F-scores\n",
    "plt.barh(selected_feature_names, [scores[i] for i in selected_indices], color='skyblue', edgecolor='black')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel(\"F-score\", fontsize=16)\n",
    "plt.title(f\"Top {k} Features via SelectKBest (ANOVA F-test)\", fontsize=20)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Add gridlines for better readability\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust tick label sizes\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df117a-0bd0-4dcb-a30f-b437461cbd49",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c35f65-4413-4f64-b45e-090b05bcca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models dictionary to save best models\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a02590-561b-4ffb-aceb-870f3277bda1",
   "metadata": {},
   "source": [
    "### 4.1 Decision Tree Classifier with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a442e8-b664-4a42-ac13-ce58d2c80a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier with GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "dt_params = {\n",
    "    'max_depth': [ 10],\n",
    "    'criterion': ['gini']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "dt = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    dt_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "dt.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save best model\n",
    "models['Decision Tree'] = dt.best_estimator_\n",
    "\n",
    "print(\"Decision Tree training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3654dcb-b621-4a36-abed-de2e5f7615b5",
   "metadata": {},
   "source": [
    "### 4.2 Random Forest Classifier with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1007f6-7762-48ed-b92d-ea56018fa916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_params = {'n_estimators': [100], 'max_depth': [20]}\n",
    "\n",
    "# GridSearchCV\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=3, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# Fit model\n",
    "rf.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save best model\n",
    "models['Random Forest'] = rf.best_estimator_\n",
    "\n",
    "print(\"Random Forest training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c187068-ca00-4520-9508-685a4e0e62ba",
   "metadata": {},
   "source": [
    "### 4.3 Logistic Regression with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e22f9f-8280-439c-a566-69fe116a9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr_params = {'C': [1]}\n",
    "\n",
    "# GridSearchCV with L2 penalty\n",
    "lr = GridSearchCV(\n",
    "    LogisticRegression(penalty='l2', max_iter=1000, random_state=42),\n",
    "    lr_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "lr.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save the best estimator\n",
    "models['Logistic Regression'] = lr.best_estimator_\n",
    "\n",
    "print(\"Logistic Regression training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeff96f-4424-44df-956e-2608e3340995",
   "metadata": {},
   "source": [
    "### 4.4 KNN with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92deb467-5639-41a5-9045-4e0d74de71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KNN parameter grid\n",
    "knn_params = {\n",
    "    'n_neighbors': [5],\n",
    "    'weights': ['distance']\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV\n",
    "knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    knn_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "knn.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save best model\n",
    "models['KNN'] = knn.best_estimator_\n",
    "\n",
    "print(\"K-Nearest Neighbors training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f8614f-bb69-4c97-978f-e4acdbf410d6",
   "metadata": {},
   "source": [
    "### 4.5 Gradient Boosting Classifier with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1ef3a-6071-487d-a139-e04a2d21175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "gbc_params = {\n",
    "    'n_estimators': [100],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "gbc = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    gbc_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "gbc.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save best model\n",
    "models['Gradient Boosting'] = gbc.best_estimator_\n",
    "\n",
    "print(\"Gradient Boosting training complete and model saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b456c8-63f7-41ce-b9d9-3066e0d93a7b",
   "metadata": {},
   "source": [
    "### 4.6 Support Vector Machine (SVM) with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec72100-1f09-4942-a207-1b5956ece449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "svm_params = {\n",
    "    'C': [1],\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "svm = GridSearchCV(\n",
    "    SVC(probability=True, random_state=42),\n",
    "    svm_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "svm.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save best model\n",
    "models['SVM'] = svm.best_estimator_\n",
    "\n",
    "print(\"Support Vector Machine training complete and model saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978dd4ef-2d4c-4834-af23-961ac4b8d458",
   "metadata": {},
   "source": [
    "### 4.7 XGBoost with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8960c-accd-47e0-bb7f-5e8db17b3d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define parameter grid\n",
    "xgb_params = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [5],\n",
    "    'learning_rate': [0.1],\n",
    "    'subsample': [0.8, 1]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "xgb = GridSearchCV(\n",
    "    estimator=XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    param_grid=xgb_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "xgb.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save best model\n",
    "models['XGBoost'] = xgb.best_estimator_\n",
    "\n",
    "print(\"XGBoost training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f6f08-5330-4a93-b3e3-dacb824bf097",
   "metadata": {},
   "source": [
    "### 4.8 Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dcb728-b9ec-48f9-abe3-ee2ed6325175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base learners (we can use simpler or diverse models)\n",
    "base_learners = [\n",
    "    ('decision_tree', models['Decision Tree']),\n",
    "    ('knn', models['KNN']),\n",
    "    ('svm', models['SVM'])\n",
    "]\n",
    "\n",
    "# Define meta-learner\n",
    "meta_learner = LogisticRegression(random_state=42, max_iter=5000)\n",
    "\n",
    "# Initialize Stacking Classifier\n",
    "stacking = StackingClassifier(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=meta_learner,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    passthrough=True\n",
    ")\n",
    "\n",
    "# Fit stacking model\n",
    "stacking.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save stacking model\n",
    "models['Stacking'] = stacking\n",
    "\n",
    "print(\"Stacking Classifier training complete and model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
